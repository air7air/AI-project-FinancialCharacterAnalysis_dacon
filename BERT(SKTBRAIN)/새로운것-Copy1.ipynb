{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"새로운것-Copy1.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hkKvIZDH0eNQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":692},"outputId":"da7f5ea3-9cc2-4399-a421-fdae342c377a","executionInfo":{"status":"ok","timestamp":1578733657200,"user_tz":-540,"elapsed":19012,"user":{"displayName":"천성욱","photoUrl":"","userId":"08465277341498786357"}}},"source":["!pip install gluonnlp\n","!pip install mxnet\n","!pip install git+https://github.com/SKTBrain/KoBERT.git\n","!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gluonnlp in /usr/local/lib/python3.6/dist-packages (0.8.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.17.5)\n","Requirement already satisfied: mxnet in /usr/local/lib/python3.6/dist-packages (1.5.1.post0)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.17.5)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet) (0.8.4)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.21.0)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2019.11.28)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Collecting git+https://github.com/SKTBrain/KoBERT.git\n","  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-req-build-_wlzr7u5\n","  Running command git clone -q https://github.com/SKTBrain/KoBERT.git /tmp/pip-req-build-_wlzr7u5\n","Requirement already satisfied (use --upgrade to upgrade): kobert==0.1.1 from git+https://github.com/SKTBrain/KoBERT.git in /usr/local/lib/python3.6/dist-packages\n","Building wheels for collected packages: kobert\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.1.1-cp36-none-any.whl size=12854 sha256=aa202899343f8201b0794c8c9136df5b68c32169d002aab7fb72ee4e82da3246\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-w1_ntx6_/wheels/66/e4/b5/36e09ef80d4682609c600c7dc9f466fc2373bba4f378dbf6ec\n","Successfully built kobert\n","Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.3.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.47)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.47)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (2.6.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wyf0QYJ125Z5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"fd0aaf2e-d4f2-4e38-bc6f-3e4db3023ef6","executionInfo":{"status":"ok","timestamp":1578733660036,"user_tz":-540,"elapsed":5255,"user":{"displayName":"천성욱","photoUrl":"","userId":"08465277341498786357"}}},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6KmBe4Muz5Df","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":62},"outputId":"ebf36a25-5c0c-45c1-8d8a-983c8a1c4f16","executionInfo":{"status":"ok","timestamp":1578733279115,"user_tz":-540,"elapsed":2749,"user":{"displayName":"천성욱","photoUrl":"","userId":"08465277341498786357"}}},"source":["from datetime import datetime\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","import math\n","from gluonnlp.data import SentencepieceTokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","from kobert.utils import get_tokenizer\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","# Dataset\n","# https://github.com/e9t/nsmc.git\n","\n","# BERT Model\n","# https://github.com/SKTBrain/KoBERT\n","\n","# Optimizer\n","# https://github.com/huggingface/pytorch-transformers#optimizers-bertadam--openaiadam-are-now-adamw-schedules-are-standard-pytorch-schedules"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"6E9SGWyLz5Dl","colab_type":"code","colab":{}},"source":["def train(train_loader, device, model, linear, all_params, optimizer, scheduler,\n","          dropout_rate, max_grad_norm, log_interval, epoch):\n","    model.train()\n","    linear.train()\n","    for batch_idx, (input_ids, token_type_ids, input_mask, target) \\\n","            in enumerate(train_loader):\n","        input_ids = input_ids.to(device)\n","        token_type_ids = token_type_ids.to(device)\n","        input_mask = input_mask.to(device)\n","        target = target.to(device)\n","\n","        optimizer.zero_grad()\n","        _, pooled_output = model(input_ids, token_type_ids, input_mask)\n","        logits = linear(F.dropout(pooled_output, p=dropout_rate))\n","        output = F.log_softmax(logits, dim=1)\n","\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(all_params, max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()\n","\n","        pred = output.argmax(dim=1, keepdim=True)\n","        correct = pred.eq(target.view_as(pred)).sum().item()\n","\n","        if (batch_idx + 1) % log_interval == 0 \\\n","                or batch_idx == len(train_loader) - 1:\n","            batch_len = len(input_ids)\n","            lr = ''\n","            for param_group in optimizer.param_groups:\n","                if 'lr' in param_group:\n","                    lr = param_group['lr']\n","                    break\n","            print('{}\\tTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'\n","                  '\\tAccuracy: {}/{} ({:.2f}%)\\tlr: {:.3e}'.format(\n","                    datetime.now(),\n","                    epoch, (batch_idx + 1) * batch_len,\n","                    len(train_loader.dataset),\n","                    100. * (batch_idx + 1) / len(train_loader), loss.item(),\n","                    correct, batch_len, 100. * correct / batch_len,\n","                    lr))\n","\n","\n","def test(test_loader, device, model, linear):\n","    model.eval()\n","    linear.eval()\n","    eval_loss = 0.\n","    correct = 0\n","    start_t = datetime.now()\n","    with torch.no_grad():\n","        for batch_idx, (input_ids, token_type_ids, input_mask, target) \\\n","                in enumerate(test_loader):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            input_mask = input_mask.to(device)\n","            target = target.to(device)\n","\n","            _, pooled_output = model(input_ids, token_type_ids, input_mask)\n","            logits = linear(pooled_output)\n","            output = F.log_softmax(logits, dim=1)\n","\n","            eval_loss += F.nll_loss(output, target, reduction='sum').item()\n","            pred = output.argmax(1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    eval_loss /= len(test_loader.dataset)\n","    acc = correct / len(test_loader.dataset)\n","    print('Elapsed time: {}, Test, Avg. Loss: {:.6f}, '\n","          'Accuracy: {}/{} ({:.2f}%)\\n'.format(datetime.now() - start_t,\n","                                               eval_loss,\n","                                               correct,\n","                                               len(test_loader.dataset),\n","                                               100. * acc))\n","\n","\n","class MovieDataset(Dataset):\n","    def __init__(self, examples):\n","        self.examples = examples\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, index):\n","        return self.examples[index]\n","\n","\n","def batchify(b):\n","    x_len = [len(e[0]) for e in b]\n","    batch_max_len = max(x_len)\n","\n","    x = list()\n","    tk_type_ids = list()\n","    x_mask = list()\n","    y = list()\n","    for e in b:\n","        seq_len = len(e[0])\n","        e0_mask = [1] * seq_len  # 1: MASK\n","        while len(e[0]) < batch_max_len:\n","            e[0].append(0)  # 0: '[PAD]'\n","            e0_mask.append(0)\n","        assert len(e[0]) == batch_max_len\n","\n","        e0_tk_type_ids = [0] * batch_max_len  #\n","        # e0_tk_type_ids[seq_len - 1] = 1\n","\n","        x.append(e[0])\n","        tk_type_ids.append(e0_tk_type_ids)\n","        x_mask.append(e0_mask)\n","        y.append(e[1])\n","\n","    x = torch.tensor(x, dtype=torch.int64)\n","    tk_type_ids = torch.tensor(tk_type_ids, dtype=torch.int64)\n","    x_mask = torch.tensor(x_mask, dtype=torch.int64)\n","    y = torch.tensor(y, dtype=torch.int64)\n","\n","    return x, tk_type_ids, x_mask, y\n","\n","\n","def get_data(filepath, vocab, sp):\n","    data = list()\n","    max_seq_len = 0\n","    with open(filepath, 'r', encoding='euc-kr') as f:\n","        for lidx, l in enumerate(f):\n","            if 0 == lidx:\n","                continue\n","            cols = l[:-1].split('\\t')\n","            # docid = cols[0]\n","            doc = cols[1]\n","            label = cols[2]\n","\n","            token_ids = list()\n","            token_ids.append(vocab['[CLS]'])\n","            for t in sp(doc):\n","                if t in vocab:\n","                    token_ids.append(vocab[t])\n","                else:\n","                    token_ids.append(vocab['[UNK]'])\n","            token_ids.append(vocab['[SEP]'])\n","\n","            data.append([token_ids, int(label)])\n","\n","            if max_seq_len < len(token_ids):\n","                max_seq_len = len(token_ids)\n","    print('max_seq_len', max_seq_len)\n","    return data\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oPnI3rQy1OBv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"2b80904f-dfad-437b-cbd2-acd64574f895","executionInfo":{"status":"ok","timestamp":1578733247272,"user_tz":-540,"elapsed":44817,"user":{"displayName":"천성욱","photoUrl":"","userId":"08465277341498786357"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pVFDUSGk1oxf","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/content/drive/My Drive/금융문자/모델링/model_BERT(SKTBrain)/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WlZ1gXJA2UO0","colab_type":"code","colab":{}},"source":["ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NH-7VGqF2l47","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":354},"outputId":"1a4b2235-626a-46ca-d8f4-be517221c706","executionInfo":{"status":"error","timestamp":1578733589316,"user_tz":-540,"elapsed":7430,"user":{"displayName":"천성욱","photoUrl":"","userId":"08465277341498786357"}}},"source":["model, vocab = get_pytorch_kobert_model(\n","        ctx='cuda')# if torch.cuda.is_available() else 'cpu')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["using cached model\n","using cached model\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-f298377d4597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model, vocab = get_pytorch_kobert_model(\n\u001b[0;32m----> 2\u001b[0;31m         ctx='cuda')# if torch.cuda.is_available() else 'cpu')\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kobert/pytorch_kobert.py\u001b[0m in \u001b[0;36mget_pytorch_kobert_model\u001b[0;34m(ctx, cachedir)\u001b[0m\n\u001b[1;32m     62\u001b[0m                            \u001b[0mvocab_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chksum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                            cachedir=cachedir)\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_kobert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kobert/pytorch_kobert.py\u001b[0m in \u001b[0;36mget_kobert_model\u001b[0;34m(model_file, vocab_file, ctx)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mbertmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mbertmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mbertmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     vocab_b_obj = nlp.vocab.BERTVocab.from_sentencepiece(vocab_file,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    192\u001b[0m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0m_cudart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudaGetErrorName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (100) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:50"]}]},{"cell_type":"code","metadata":{"id":"c4bno9ja2p00","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"b38fe146-8419-4950-b1c6-1a6ebfba2dcc","executionInfo":{"status":"ok","timestamp":1578733613840,"user_tz":-540,"elapsed":5391,"user":{"displayName":"천성욱","photoUrl":"","userId":"08465277341498786357"}}},"source":["!nvidia-smi"],"execution_count":21,"outputs":[{"output_type":"stream","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KxfX6kO2z5Dp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":118},"outputId":"48d983f8-18b3-4f9a-9b43-7bd4c45d917a","executionInfo":{"status":"error","timestamp":1578733579607,"user_tz":-540,"elapsed":81192,"user":{"displayName":"천성욱","photoUrl":"","userId":"08465277341498786357"}}},"source":["def main():\n","#     nsmc_home_dir = '/media/donghyeon/f7c53837-2156-4793-b2b1-4b0578dffef1/nlp/nsmc'\n","    train_file = \"30000train.txt\"  # 150K\n","    test_file = \"30000test.txt\"  # 50K\n","\n","    # model, vocab = get_pytorch_kobert_model(\n","    #     ctx='cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    lr = 5e-5\n","    batch_size = 16\n","    epochs = 5\n","    dropout_rate = 0.1\n","    max_grad_norm = 1.0\n","    num_total_steps = math.ceil(150000 / batch_size) * epochs\n","    num_warmup_steps = num_total_steps // 10\n","    log_interval = 100\n","    seed = 2019\n","    num_workers = 2\n","    num_classes = 2\n","    pooler_out_dim = model.pooler.dense.out_features\n","\n","    torch.manual_seed(seed)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    print('device', device)\n","\n","    tok_path = get_tokenizer()\n","    sp = SentencepieceTokenizer(tok_path)\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        MovieDataset(get_data(train_file, vocab, sp)),\n","        shuffle=True,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        collate_fn=batchify,\n","        pin_memory=True\n","    )\n","\n","    test_loader = torch.utils.data.DataLoader(\n","        MovieDataset(get_data(test_file, vocab, sp)),\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=num_workers,\n","        collate_fn=batchify,\n","        pin_memory=True\n","    )\n","\n","    linear = torch.nn.Linear(pooler_out_dim, num_classes).to(device)\n","\n","    all_params = list(model.parameters()) + list(linear.parameters())\n","    optimizer = AdamW(all_params, lr=lr, correct_bias=False)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps,\n","                                     num_training_steps=num_total_steps)\n","\n","    for epoch in range(epochs):\n","        train(train_loader, device, model, linear, all_params,\n","              optimizer, scheduler, dropout_rate, max_grad_norm,\n","              log_interval, epoch)\n","        print(datetime.now(), 'Testing...')\n","        test(test_loader, device, model, linear)\n","\n","\n","if __name__ == '__main__':\n","    main()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[██████████████████████████████████████████████████]\n","[██████████████████████████████████████████████████]\n","device cpu\n","using cached model\n","max_seq_len 1236\n","max_seq_len 725\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DjU4a78j0zIf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A99sCZGUz5Dt","colab_type":"code","colab":{}},"source":["torch.save(model, 'kobert_new_30000_front_back_1epochs')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DJ2rnaeEz5Dw","colab_type":"code","colab":{},"outputId":"947038d3-04aa-4c1b-84c1-da5e487d9ada"},"source":["model, vocab = get_pytorch_kobert_model()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["using cached model\n","using cached model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gsOxc_ELz5D1","colab_type":"code","colab":{}},"source":["# model load"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t143cR6kz5D5","colab_type":"code","colab":{},"outputId":"d815994a-0515-464a-a8fa-43019bbd1acc"},"source":["vocab.bos_token"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'a' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-76-e973c920c55f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"]}]},{"cell_type":"code","metadata":{"id":"D-M6QKYWz5D8","colab_type":"code","colab":{}},"source":["model = torch.load('kobert_new_30000_front_back_1epochs')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"vg3ufy3Zz5D_","colab_type":"code","colab":{},"outputId":"09a2d485-1a53-4224-c294-b66461dfc834"},"source":["class MovieDataset(Dataset):\n","    def __init__(self, examples):\n","        self.examples = examples\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, index):\n","        return self.examples[index]\n","###########################################\n","\n","test_file = \"/home/ec2-user/workspace/Members/KSA/newdirectory/neew.txt\"  \n","\n","# model, vocab = get_pytorch_kobert_model('cpu')\n","#     ctx='cuda' if torch.cuda.is_available() else 'cpu')\n","\n","lr = 5e-5\n","batch_size = 1\n","epochs = 5\n","dropout_rate = 0.1\n","max_grad_norm = 1.0\n","num_total_steps = math.ceil(150000 / batch_size) * epochs\n","num_warmup_steps = num_total_steps // 10\n","log_interval = 100\n","seed = 2019\n","num_workers = 2\n","num_classes = 2\n","pooler_out_dim = model.pooler.dense.out_features\n","\n","torch.manual_seed(seed)\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device = torch.device(\"cpu\")\n","\n","print('device', device)\n","\n","tok_path = get_tokenizer()\n","sp = SentencepieceTokenizer(tok_path)\n","\n","\n","test_loader = torch.utils.data.DataLoader(\n","    MovieDataset(get_data(test_file, vocab, sp)),\n","    batch_size=batch_size,\n","    shuffle=False,\n","    num_workers=num_workers,\n","    collate_fn=batchify,\n","    pin_memory=True\n",")\n","\n","\n","linear = torch.nn.Linear(pooler_out_dim, num_classes).to(device)\n","\n"," "],"execution_count":0,"outputs":[{"output_type":"stream","text":["device cpu\n","using cached model\n","max_seq_len 757\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q1G0eMn2z5EC","colab_type":"code","colab":{}},"source":["device_cpu = torch.device(\"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"ZWURiQuDz5EG","colab_type":"code","colab":{},"outputId":"5d7fdbb4-8dd9-44b4-efc5-e67e688e6251"},"source":["import numpy as np\n","\n","for batch_id, (input_ids, token_type_ids, input_mask,target) in enumerate(test_loader):\n","#     if batch_id==1:\n","#         break\n","    model.eval()\n","#     print(target)\n","    input_ids = input_ids.long().to(device_cpu) ##\n","    input_mask = input_mask.long().to(device_cpu)  ##\n","    token_type_ids= token_type_ids.to(device_cpu)  ##\n","#     print(token_type_ids)\n","    \n","#     out = model(token_ids, valid_length, segment_ids)\n","#     logits=out[0]\n","    _, pooled_output = model(input_ids, token_type_ids, input_mask)\n","    logits = linear(pooled_output)\n","#     print(logits)\n","    output = F.softmax(logits[0])#, dim=1)\n","#     print(\"logits.shape\",logits.shape)\n","#     logits = logits.cpu().detach().numpy()\n","#     print(logits)\n","#     a=np.exp(logits[0].cpu().detach().numpy()) + np.exp(logits[1].cpu().detach().numpy())\n","#     b=np.exp(logits[1].cpu().detach().numpy())\n","\n","    print(output)\n","#     print (b/a)   "],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["tensor([0.3639, 0.6361], grad_fn=<SoftmaxBackward>)\n","tensor([0.3678, 0.6322], grad_fn=<SoftmaxBackward>)\n","tensor([0.4679, 0.5321], grad_fn=<SoftmaxBackward>)\n","tensor([0.4358, 0.5642], grad_fn=<SoftmaxBackward>)\n","tensor([0.3705, 0.6295], grad_fn=<SoftmaxBackward>)\n","tensor([0.3521, 0.6479], grad_fn=<SoftmaxBackward>)\n","tensor([0.3633, 0.6367], grad_fn=<SoftmaxBackward>)\n","tensor([0.3438, 0.6562], grad_fn=<SoftmaxBackward>)\n","tensor([0.4384, 0.5616], grad_fn=<SoftmaxBackward>)\n","tensor([0.3391, 0.6609], grad_fn=<SoftmaxBackward>)\n","tensor([0.3825, 0.6175], grad_fn=<SoftmaxBackward>)\n","tensor([0.3332, 0.6668], grad_fn=<SoftmaxBackward>)\n","tensor([0.3548, 0.6452], grad_fn=<SoftmaxBackward>)\n","tensor([0.3480, 0.6520], grad_fn=<SoftmaxBackward>)\n","tensor([0.3480, 0.6520], grad_fn=<SoftmaxBackward>)\n","tensor([0.3487, 0.6513], grad_fn=<SoftmaxBackward>)\n","tensor([0.3678, 0.6322], grad_fn=<SoftmaxBackward>)\n","tensor([0.3622, 0.6378], grad_fn=<SoftmaxBackward>)\n","tensor([0.3505, 0.6495], grad_fn=<SoftmaxBackward>)\n","tensor([0.4290, 0.5710], grad_fn=<SoftmaxBackward>)\n","tensor([0.3652, 0.6348], grad_fn=<SoftmaxBackward>)\n","tensor([0.4589, 0.5411], grad_fn=<SoftmaxBackward>)\n","tensor([0.3550, 0.6450], grad_fn=<SoftmaxBackward>)\n","tensor([0.3524, 0.6476], grad_fn=<SoftmaxBackward>)\n","tensor([0.3658, 0.6342], grad_fn=<SoftmaxBackward>)\n","tensor([0.4341, 0.5659], grad_fn=<SoftmaxBackward>)\n","tensor([0.4174, 0.5826], grad_fn=<SoftmaxBackward>)\n","tensor([0.3424, 0.6576], grad_fn=<SoftmaxBackward>)\n","tensor([0.3541, 0.6459], grad_fn=<SoftmaxBackward>)\n","tensor([0.4394, 0.5606], grad_fn=<SoftmaxBackward>)\n","tensor([0.4454, 0.5546], grad_fn=<SoftmaxBackward>)\n","tensor([0.3924, 0.6076], grad_fn=<SoftmaxBackward>)\n","tensor([0.3626, 0.6374], grad_fn=<SoftmaxBackward>)\n","tensor([0.3544, 0.6456], grad_fn=<SoftmaxBackward>)\n","tensor([0.3676, 0.6324], grad_fn=<SoftmaxBackward>)\n","tensor([0.3628, 0.6372], grad_fn=<SoftmaxBackward>)\n","tensor([0.3556, 0.6444], grad_fn=<SoftmaxBackward>)\n","tensor([0.4476, 0.5524], grad_fn=<SoftmaxBackward>)\n","tensor([0.4799, 0.5201], grad_fn=<SoftmaxBackward>)\n","tensor([0.3532, 0.6468], grad_fn=<SoftmaxBackward>)\n","tensor([0.3361, 0.6639], grad_fn=<SoftmaxBackward>)\n","tensor([0.3633, 0.6367], grad_fn=<SoftmaxBackward>)\n","tensor([0.3309, 0.6691], grad_fn=<SoftmaxBackward>)\n","tensor([0.3558, 0.6442], grad_fn=<SoftmaxBackward>)\n","tensor([0.3800, 0.6200], grad_fn=<SoftmaxBackward>)\n","tensor([0.3762, 0.6238], grad_fn=<SoftmaxBackward>)\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"index out of range: Tried to access index 512 out of table with 511 rows. at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:418","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-40c5d9741729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#     out = model(token_ids, valid_length, segment_ids)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#     logits=out[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#     print(logits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         encoder_outputs = self.encoder(embedding_output,\n\u001b[1;32m    716\u001b[0m                                        \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: index out of range: Tried to access index 512 out of table with 511 rows. at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:418"]}]},{"cell_type":"code","metadata":{"id":"LzStVCOnz5EK","colab_type":"code","colab":{},"outputId":"ef5d9669-623e-4013-a0a2-018c2fc2a960"},"source":["logits[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.3827,  0.2152], grad_fn=<SelectBackward>)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"s_TUOmdNz5EN","colab_type":"code","colab":{},"outputId":"ae5b7ff3-b850-4261-df59-3f944794eeab"},"source":["F.softmax(logits[0]).sum()#, dim=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["tensor(1., grad_fn=<SumBackward0>)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"yTtAOefxz5EQ","colab_type":"code","colab":{},"outputId":"59f41398-c7df-40d8-f192-a58eeac57fb6"},"source":["a, b =[-0.7594, -0.6310]\n","a, b"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(-0.7594, -0.631)"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"8hueFaEWz5EU","colab_type":"code","colab":{},"outputId":"6b7ef108-247c-4f12-82c3-92cffe07afc2"},"source":["softmax(a,b)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'softmax' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-5fc80c646077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'softmax' is not defined"]}]},{"cell_type":"code","metadata":{"id":"wxXdgjubz5Ec","colab_type":"code","colab":{}},"source":["# 바꾸기전\n","#######\n","# import numpy as np\n","\n","# for batch_id, (input_ids, token_type_ids, input_mask,target) in enumerate(test_loader):\n","#     if batch_id==1:\n","#         break\n","#     model.eval()\n","#     print(label)\n","#     token_ids = token_ids.long().to(device) ##\n","#     segment_ids = segment_ids.long().to(device)  ##\n","#     valid_length= valid_length.to(device)  ##\n","#     print(valid_length)\n","    \n","# #     out = model(token_ids, valid_length, segment_ids)\n","# #     logits=out[0]\n","#     _, pooled_output = model(token_ids, valid_length, segment_ids)\n","#     logits = linear(pooled_output)\n","#     output = F.log_softmax(logits, dim=1)\n","# #     print(\"logits.shape\",logits.shape)\n","# #     logits = logits.cpu().detach().numpy()\n","# #     print(logits)\n","# #     a=np.exp(logits[0].cpu().detach().numpy()) + np.exp(logits[1].cpu().detach().numpy())\n","# #     b=np.exp(logits[1].cpu().detach().numpy())\n","\n","#     print(output)\n","# #     print (b/a)   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ph98TV9z5Eg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B4gMNwLkz5Ej","colab_type":"code","colab":{}},"source":["#여기서부터 연습\n","max_len = 128\n","dataset_ttest = nlp.data.TSVDataset(\"neew.txt\", field_indices=[1,2], num_discard_samples=1, encoding='cp949')\n","data_ttest = BERTDataset(dataset_ttest, 0, 1, tok, max_len, True, False)    \n","\n","#차원 축소\n","ttrain_dataloader=torch.utils.data.DataLoader(data_ttest, batch_size=1, num_workers=5)\n","\n","\n","\n","for batch_id, (token_ids, valid_length, segment_ids,label) in enumerate(ttrain_dataloader):\n","\n","    model.eval()\n","    \n","    token_ids = token_ids.long().to(device) ##\n","    segment_ids = segment_ids.long().to(device)  ##\n","    valid_length= valid_length ##\n","#     label = label.long().to(device) ##\n","\n","    with torch.no_grad():     \n","        out = model(token_ids, valid_length, segment_ids)\n","    logits=out[0]\n","#     print(\"logits.shape\",logits.shape)\n","    logits = logits.cpu().detach().numpy()\n","#     print(logits)\n","    a=np.exp(logits[0]) + np.exp(logits[1])\n","    b=np.exp(logits[1])\n","\n","\n","    print (b/a)    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TimMH5k8z5Em","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VAmg02ehz5Ep","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YLHDJuZKz5Et","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UZwsQlehz5Ex","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNdGBSOtz5E1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6-OA5PYwz5E4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i1R1tphTz5E7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}