{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[연습]_colab_bert_finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FmUNlyUrTCad"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8ebTsFBQRHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [연습]_colab_bert_finetuning.ipynb\n",
        "# 200102(목) 12:17~\n",
        "# 천성욱"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpRdsFF4QR_R",
        "colab_type": "code",
        "outputId": "60b3f5ae-cdf9-4d6d-d258-f9676f5bac03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwEVnjmwQDCV",
        "colab_type": "code",
        "outputId": "ed77bb44-d745-4fe0-e7fb-98cd1a1a5090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "!pip install transformers==2.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/e7/0a1babead1b79afabb654fbec0a052e0d833ba4205a6dfd98b1aeda9c82e/transformers-2.2.0-py3-none-any.whl (360kB)\n",
            "\r\u001b[K     |█                               | 10kB 27.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 5.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 40kB 5.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 51kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 61kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 71kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 81kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 92kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 102kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 112kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 122kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 133kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 143kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 153kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 163kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 174kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 184kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 194kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 204kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 215kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 225kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 235kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 245kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 256kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 266kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 276kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 286kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 296kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 307kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 317kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 327kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 337kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 348kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 358kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 368kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.2) (2.21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 65.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.2) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.2) (1.17.4)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 30.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers==2.2) (2019.12.9)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.2) (1.10.40)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.2) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.2) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.2) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.2) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.2) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.2) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.2) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.2) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.2) (1.13.40)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers==2.2) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers==2.2) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=c16010f7d3fc1ebd3232df05b6f4b84799f9e8521a860d79000c1c04069772e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.35 sentencepiece-0.1.85 transformers-2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzVXdBD7P_mV",
        "colab_type": "code",
        "outputId": "1ca176b3-85eb-470c-8e23-f2520835653f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "# from transformers import WarmupLinearSchedule as get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVtk3tCtQI27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tor_odic_weights = torch.load('/content/drive/My Drive/금융문자/모델링/model_KorBERT(ETRI)/1_bert_download_001_bert_morp_pytorch/001_bert_morp_pytorch/pytorch_model.bin')\n",
        "dic_weights = dict(tor_odic_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h521aggnQOig",
        "colab_type": "code",
        "outputId": "980f5a27-8236-4f28-beba-f8c4126eb0ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "d_weight_new = dict()\n",
        "int_lcnt_f = len(list(dic_weights.items())) -8    # BERT 모델 부분만 로드하기 위해서 8을 빼야한다.\n",
        "for idx, (k, v) in enumerate(dic_weights.items()):\n",
        "    if idx ==  int_lcnt_f:\n",
        "        break\n",
        "    print(k[5:])\n",
        "    d_weight_new[k[5:]] = v"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embeddings.word_embeddings.weight\n",
            "embeddings.position_embeddings.weight\n",
            "embeddings.token_type_embeddings.weight\n",
            "embeddings.LayerNorm.weight\n",
            "embeddings.LayerNorm.bias\n",
            "encoder.layer.0.attention.self.query.weight\n",
            "encoder.layer.0.attention.self.query.bias\n",
            "encoder.layer.0.attention.self.key.weight\n",
            "encoder.layer.0.attention.self.key.bias\n",
            "encoder.layer.0.attention.self.value.weight\n",
            "encoder.layer.0.attention.self.value.bias\n",
            "encoder.layer.0.attention.output.dense.weight\n",
            "encoder.layer.0.attention.output.dense.bias\n",
            "encoder.layer.0.attention.output.LayerNorm.weight\n",
            "encoder.layer.0.attention.output.LayerNorm.bias\n",
            "encoder.layer.0.intermediate.dense.weight\n",
            "encoder.layer.0.intermediate.dense.bias\n",
            "encoder.layer.0.output.dense.weight\n",
            "encoder.layer.0.output.dense.bias\n",
            "encoder.layer.0.output.LayerNorm.weight\n",
            "encoder.layer.0.output.LayerNorm.bias\n",
            "encoder.layer.1.attention.self.query.weight\n",
            "encoder.layer.1.attention.self.query.bias\n",
            "encoder.layer.1.attention.self.key.weight\n",
            "encoder.layer.1.attention.self.key.bias\n",
            "encoder.layer.1.attention.self.value.weight\n",
            "encoder.layer.1.attention.self.value.bias\n",
            "encoder.layer.1.attention.output.dense.weight\n",
            "encoder.layer.1.attention.output.dense.bias\n",
            "encoder.layer.1.attention.output.LayerNorm.weight\n",
            "encoder.layer.1.attention.output.LayerNorm.bias\n",
            "encoder.layer.1.intermediate.dense.weight\n",
            "encoder.layer.1.intermediate.dense.bias\n",
            "encoder.layer.1.output.dense.weight\n",
            "encoder.layer.1.output.dense.bias\n",
            "encoder.layer.1.output.LayerNorm.weight\n",
            "encoder.layer.1.output.LayerNorm.bias\n",
            "encoder.layer.2.attention.self.query.weight\n",
            "encoder.layer.2.attention.self.query.bias\n",
            "encoder.layer.2.attention.self.key.weight\n",
            "encoder.layer.2.attention.self.key.bias\n",
            "encoder.layer.2.attention.self.value.weight\n",
            "encoder.layer.2.attention.self.value.bias\n",
            "encoder.layer.2.attention.output.dense.weight\n",
            "encoder.layer.2.attention.output.dense.bias\n",
            "encoder.layer.2.attention.output.LayerNorm.weight\n",
            "encoder.layer.2.attention.output.LayerNorm.bias\n",
            "encoder.layer.2.intermediate.dense.weight\n",
            "encoder.layer.2.intermediate.dense.bias\n",
            "encoder.layer.2.output.dense.weight\n",
            "encoder.layer.2.output.dense.bias\n",
            "encoder.layer.2.output.LayerNorm.weight\n",
            "encoder.layer.2.output.LayerNorm.bias\n",
            "encoder.layer.3.attention.self.query.weight\n",
            "encoder.layer.3.attention.self.query.bias\n",
            "encoder.layer.3.attention.self.key.weight\n",
            "encoder.layer.3.attention.self.key.bias\n",
            "encoder.layer.3.attention.self.value.weight\n",
            "encoder.layer.3.attention.self.value.bias\n",
            "encoder.layer.3.attention.output.dense.weight\n",
            "encoder.layer.3.attention.output.dense.bias\n",
            "encoder.layer.3.attention.output.LayerNorm.weight\n",
            "encoder.layer.3.attention.output.LayerNorm.bias\n",
            "encoder.layer.3.intermediate.dense.weight\n",
            "encoder.layer.3.intermediate.dense.bias\n",
            "encoder.layer.3.output.dense.weight\n",
            "encoder.layer.3.output.dense.bias\n",
            "encoder.layer.3.output.LayerNorm.weight\n",
            "encoder.layer.3.output.LayerNorm.bias\n",
            "encoder.layer.4.attention.self.query.weight\n",
            "encoder.layer.4.attention.self.query.bias\n",
            "encoder.layer.4.attention.self.key.weight\n",
            "encoder.layer.4.attention.self.key.bias\n",
            "encoder.layer.4.attention.self.value.weight\n",
            "encoder.layer.4.attention.self.value.bias\n",
            "encoder.layer.4.attention.output.dense.weight\n",
            "encoder.layer.4.attention.output.dense.bias\n",
            "encoder.layer.4.attention.output.LayerNorm.weight\n",
            "encoder.layer.4.attention.output.LayerNorm.bias\n",
            "encoder.layer.4.intermediate.dense.weight\n",
            "encoder.layer.4.intermediate.dense.bias\n",
            "encoder.layer.4.output.dense.weight\n",
            "encoder.layer.4.output.dense.bias\n",
            "encoder.layer.4.output.LayerNorm.weight\n",
            "encoder.layer.4.output.LayerNorm.bias\n",
            "encoder.layer.5.attention.self.query.weight\n",
            "encoder.layer.5.attention.self.query.bias\n",
            "encoder.layer.5.attention.self.key.weight\n",
            "encoder.layer.5.attention.self.key.bias\n",
            "encoder.layer.5.attention.self.value.weight\n",
            "encoder.layer.5.attention.self.value.bias\n",
            "encoder.layer.5.attention.output.dense.weight\n",
            "encoder.layer.5.attention.output.dense.bias\n",
            "encoder.layer.5.attention.output.LayerNorm.weight\n",
            "encoder.layer.5.attention.output.LayerNorm.bias\n",
            "encoder.layer.5.intermediate.dense.weight\n",
            "encoder.layer.5.intermediate.dense.bias\n",
            "encoder.layer.5.output.dense.weight\n",
            "encoder.layer.5.output.dense.bias\n",
            "encoder.layer.5.output.LayerNorm.weight\n",
            "encoder.layer.5.output.LayerNorm.bias\n",
            "encoder.layer.6.attention.self.query.weight\n",
            "encoder.layer.6.attention.self.query.bias\n",
            "encoder.layer.6.attention.self.key.weight\n",
            "encoder.layer.6.attention.self.key.bias\n",
            "encoder.layer.6.attention.self.value.weight\n",
            "encoder.layer.6.attention.self.value.bias\n",
            "encoder.layer.6.attention.output.dense.weight\n",
            "encoder.layer.6.attention.output.dense.bias\n",
            "encoder.layer.6.attention.output.LayerNorm.weight\n",
            "encoder.layer.6.attention.output.LayerNorm.bias\n",
            "encoder.layer.6.intermediate.dense.weight\n",
            "encoder.layer.6.intermediate.dense.bias\n",
            "encoder.layer.6.output.dense.weight\n",
            "encoder.layer.6.output.dense.bias\n",
            "encoder.layer.6.output.LayerNorm.weight\n",
            "encoder.layer.6.output.LayerNorm.bias\n",
            "encoder.layer.7.attention.self.query.weight\n",
            "encoder.layer.7.attention.self.query.bias\n",
            "encoder.layer.7.attention.self.key.weight\n",
            "encoder.layer.7.attention.self.key.bias\n",
            "encoder.layer.7.attention.self.value.weight\n",
            "encoder.layer.7.attention.self.value.bias\n",
            "encoder.layer.7.attention.output.dense.weight\n",
            "encoder.layer.7.attention.output.dense.bias\n",
            "encoder.layer.7.attention.output.LayerNorm.weight\n",
            "encoder.layer.7.attention.output.LayerNorm.bias\n",
            "encoder.layer.7.intermediate.dense.weight\n",
            "encoder.layer.7.intermediate.dense.bias\n",
            "encoder.layer.7.output.dense.weight\n",
            "encoder.layer.7.output.dense.bias\n",
            "encoder.layer.7.output.LayerNorm.weight\n",
            "encoder.layer.7.output.LayerNorm.bias\n",
            "encoder.layer.8.attention.self.query.weight\n",
            "encoder.layer.8.attention.self.query.bias\n",
            "encoder.layer.8.attention.self.key.weight\n",
            "encoder.layer.8.attention.self.key.bias\n",
            "encoder.layer.8.attention.self.value.weight\n",
            "encoder.layer.8.attention.self.value.bias\n",
            "encoder.layer.8.attention.output.dense.weight\n",
            "encoder.layer.8.attention.output.dense.bias\n",
            "encoder.layer.8.attention.output.LayerNorm.weight\n",
            "encoder.layer.8.attention.output.LayerNorm.bias\n",
            "encoder.layer.8.intermediate.dense.weight\n",
            "encoder.layer.8.intermediate.dense.bias\n",
            "encoder.layer.8.output.dense.weight\n",
            "encoder.layer.8.output.dense.bias\n",
            "encoder.layer.8.output.LayerNorm.weight\n",
            "encoder.layer.8.output.LayerNorm.bias\n",
            "encoder.layer.9.attention.self.query.weight\n",
            "encoder.layer.9.attention.self.query.bias\n",
            "encoder.layer.9.attention.self.key.weight\n",
            "encoder.layer.9.attention.self.key.bias\n",
            "encoder.layer.9.attention.self.value.weight\n",
            "encoder.layer.9.attention.self.value.bias\n",
            "encoder.layer.9.attention.output.dense.weight\n",
            "encoder.layer.9.attention.output.dense.bias\n",
            "encoder.layer.9.attention.output.LayerNorm.weight\n",
            "encoder.layer.9.attention.output.LayerNorm.bias\n",
            "encoder.layer.9.intermediate.dense.weight\n",
            "encoder.layer.9.intermediate.dense.bias\n",
            "encoder.layer.9.output.dense.weight\n",
            "encoder.layer.9.output.dense.bias\n",
            "encoder.layer.9.output.LayerNorm.weight\n",
            "encoder.layer.9.output.LayerNorm.bias\n",
            "encoder.layer.10.attention.self.query.weight\n",
            "encoder.layer.10.attention.self.query.bias\n",
            "encoder.layer.10.attention.self.key.weight\n",
            "encoder.layer.10.attention.self.key.bias\n",
            "encoder.layer.10.attention.self.value.weight\n",
            "encoder.layer.10.attention.self.value.bias\n",
            "encoder.layer.10.attention.output.dense.weight\n",
            "encoder.layer.10.attention.output.dense.bias\n",
            "encoder.layer.10.attention.output.LayerNorm.weight\n",
            "encoder.layer.10.attention.output.LayerNorm.bias\n",
            "encoder.layer.10.intermediate.dense.weight\n",
            "encoder.layer.10.intermediate.dense.bias\n",
            "encoder.layer.10.output.dense.weight\n",
            "encoder.layer.10.output.dense.bias\n",
            "encoder.layer.10.output.LayerNorm.weight\n",
            "encoder.layer.10.output.LayerNorm.bias\n",
            "encoder.layer.11.attention.self.query.weight\n",
            "encoder.layer.11.attention.self.query.bias\n",
            "encoder.layer.11.attention.self.key.weight\n",
            "encoder.layer.11.attention.self.key.bias\n",
            "encoder.layer.11.attention.self.value.weight\n",
            "encoder.layer.11.attention.self.value.bias\n",
            "encoder.layer.11.attention.output.dense.weight\n",
            "encoder.layer.11.attention.output.dense.bias\n",
            "encoder.layer.11.attention.output.LayerNorm.weight\n",
            "encoder.layer.11.attention.output.LayerNorm.bias\n",
            "encoder.layer.11.intermediate.dense.weight\n",
            "encoder.layer.11.intermediate.dense.bias\n",
            "encoder.layer.11.output.dense.weight\n",
            "encoder.layer.11.output.dense.bias\n",
            "encoder.layer.11.output.LayerNorm.weight\n",
            "encoder.layer.11.output.LayerNorm.bias\n",
            "pooler.dense.weight\n",
            "pooler.dense.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rImRAnw1Q4v7",
        "colab_type": "code",
        "outputId": "e45dd4fc-f351-466f-d257-ffd26f77505d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "from collections import OrderedDict\n",
        "odic_weight_new = OrderedDict(d_weight_new)\n",
        "print(list(tor_odic_weights.items())[0])\n",
        "print(list(tor_odic_weights.items())[0][1].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('bert.embeddings.word_embeddings.weight', tensor([[-0.0276,  0.0102, -0.0276,  ...,  0.0029, -0.0093, -0.0042],\n",
            "        [-0.0470,  0.0217, -0.0154,  ..., -0.0391,  0.0253,  0.0215],\n",
            "        [-0.0147, -0.0300, -0.0310,  ..., -0.0107, -0.0058,  0.0222],\n",
            "        ...,\n",
            "        [-0.0589, -0.0076,  0.0200,  ...,  0.0097, -0.0124,  0.0145],\n",
            "        [-0.0356, -0.0602, -0.0140,  ...,  0.0230, -0.0017, -0.0488],\n",
            "        [-0.0531, -0.0201, -0.0196,  ..., -0.0237, -0.0130, -0.0030]]))\n",
            "torch.Size([30349, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu0ABVROREeK",
        "colab_type": "code",
        "outputId": "13b7813c-ba8c-4df3-e12d-dcc8a65ed936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import BertModel\n",
        "from transformers import BertConfig\n",
        "model_bert = BertModel(BertConfig(vocab_size_or_config_json_file=30349))\n",
        "model_bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30349, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdiQmj7gQ9_A",
        "colab_type": "code",
        "outputId": "6aacc15e-50b9-4943-8e0d-38e9df635f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_bert.load_state_dict(odic_weight_new)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gjQq7j_RMb8",
        "colab_type": "text"
      },
      "source": [
        "# classifier 레이어 합치기(진행중)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5oHuvkjRPEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=2,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4LrVnTQRU9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82hAus2JRQoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BERTClassifier(model_bert,  dr_rate=0.1).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBG4w_oLRhys",
        "colab_type": "code",
        "outputId": "9743dbfb-9002-41ec-d21c-67e864909a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "!nvidia-smi    # 1183MiB 차지"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jan  2 03:22:16 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    31W / 250W |   1183MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htIKk6FVR85R",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 로드 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbF4mDdNR-jd",
        "colab_type": "code",
        "outputId": "a0af57bd-416b-4b41-92e6-a9592d6c4148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 판다스로 훈련셋과 테스트셋 데이터 로드\n",
        "import pandas as pd\n",
        "path_base = '/content/drive/My Drive/금융문자/데이터/'\n",
        "train = pd.read_csv(path_base + \"sam60K_lvDist_0_82222_1_whole.csv\", encoding='utf-8')\n",
        "print(train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60037, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZCKBOKISHwS",
        "colab_type": "code",
        "outputId": "8c982526-dd0b-4ce1-a949-05462a5dedaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import re\n",
        "re_pat_space = re.compile('\\s{2,}')\n",
        "re_pat_space.sub('g', '안녕  하세       요')\n",
        "re_pat_words = re.compile('[^가-힣a-zA-Z0-9\\s]')\n",
        "re_pat_words.findall(\"녕  하세       요\")\n",
        "re_pat_XX_XXX = re.compile('X{2,}')\n",
        "print(re_pat_XX_XXX.findall('XX고객님 XXX은행입니다. 안녕  하세       요X'))\n",
        "re_pat_XX_XXX.sub('', 'XX고객님 XXX은행입니다. 안녕  하세       요X')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['XX', 'XXX']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'고객님 은행입니다. 안녕  하세       요X'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1RLyj6nSLfq",
        "colab_type": "code",
        "outputId": "24ad5b86-34bb-4495-d76c-7689df5c8ac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "source": [
        "train['text'] = train['text'].apply(lambda x: re_pat_XX_XXX.sub(' ', re_pat_space.sub(' ', re_pat_words.sub('', x))))\n",
        "train#['text']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year_month</th>\n",
              "      <th>text</th>\n",
              "      <th>smishing</th>\n",
              "      <th>prep</th>\n",
              "      <th>len</th>\n",
              "      <th>lvDist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>303496</td>\n",
              "      <td>2018-09</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>147557</td>\n",
              "      <td>2017-08</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>257777</td>\n",
              "      <td>2018-04</td>\n",
              "      <td>0415 1422 카드스마트 710000잔액4869889</td>\n",
              "      <td>0</td>\n",
              "      <td>04151422 카드스마트 710000잔액4869889</td>\n",
              "      <td>31</td>\n",
              "      <td>0.967742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84368</td>\n",
              "      <td>2017-05</td>\n",
              "      <td>0전화하셔서0번누르시면상담원연결됩니다사용자계약번호확인해주세요</td>\n",
              "      <td>0</td>\n",
              "      <td>0전화하셔서0번누르시면상담원연결됩니다사용자계약번호확인해주세요</td>\n",
              "      <td>34</td>\n",
              "      <td>0.947368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>81268</td>\n",
              "      <td>2017-05</td>\n",
              "      <td>1 입니다감사합니다 은행 올림</td>\n",
              "      <td>0</td>\n",
              "      <td>1 입니다감사합니다 은행 올림</td>\n",
              "      <td>17</td>\n",
              "      <td>0.911765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60032</th>\n",
              "      <td>308804</td>\n",
              "      <td>2018-10</td>\n",
              "      <td>햇살론대출 지원금융센터   수탁법인 투빅플러스2018년 현재 정부지원 자금을 통해 ...</td>\n",
              "      <td>1</td>\n",
              "      <td>햇살론대출지원금융센터 수탁법인투빅플러스2018년현재정부지원자금을통해하반기채무통합대환...</td>\n",
              "      <td>649</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60033</th>\n",
              "      <td>302073</td>\n",
              "      <td>2018-09</td>\n",
              "      <td>햇살론대출 지원금융센터 하나 2018년 현재 정부지원 자금을 통해 하반기 채무통합대...</td>\n",
              "      <td>1</td>\n",
              "      <td>햇살론대출지원금융센터하나 2018년현재정부지원자금을통해하반기채무통합대환상품추가상품개...</td>\n",
              "      <td>642</td>\n",
              "      <td>0.016949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60034</th>\n",
              "      <td>329779</td>\n",
              "      <td>2018-11</td>\n",
              "      <td>햇살론대출 지원금융센터 하나 2018년 현재 정부지원 자금을 통해 하반기 채무통합대...</td>\n",
              "      <td>1</td>\n",
              "      <td>햇살론대출지원금융센터하나 2018년현재정부지원자금을통해하반기채무통합대환상품추가상품개...</td>\n",
              "      <td>632</td>\n",
              "      <td>0.015576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60035</th>\n",
              "      <td>313242</td>\n",
              "      <td>2018-10</td>\n",
              "      <td>햇살론대출 지원금융센터 하나  수탁법인 하나채움2018년 현재 정부지원 자금을 통해...</td>\n",
              "      <td>1</td>\n",
              "      <td>햇살론대출지원금융센터하나 수탁법인하나채움2018년현재정부지원자금을통해하반기채무통합대...</td>\n",
              "      <td>650</td>\n",
              "      <td>0.027692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60036</th>\n",
              "      <td>334452</td>\n",
              "      <td>2018-12</td>\n",
              "      <td>햇살론 사잇돌 채무통  금융센터 하나  수탁법인 하나채움주2018년 현재 정부지원 ...</td>\n",
              "      <td>1</td>\n",
              "      <td>햇살론사잇돌채무통 금융센터하나 수탁법인하나채움주2018년현재정부지원자금을통해하반기채...</td>\n",
              "      <td>648</td>\n",
              "      <td>0.106154</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60037 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id year_month  ...  len    lvDist\n",
              "0      303496    2018-09  ...    0  1.000000\n",
              "1      147557    2017-08  ...    1  1.000000\n",
              "2      257777    2018-04  ...   31  0.967742\n",
              "3       84368    2017-05  ...   34  0.947368\n",
              "4       81268    2017-05  ...   17  0.911765\n",
              "...       ...        ...  ...  ...       ...\n",
              "60032  308804    2018-10  ...  649  0.000000\n",
              "60033  302073    2018-09  ...  642  0.016949\n",
              "60034  329779    2018-11  ...  632  0.015576\n",
              "60035  313242    2018-10  ...  650  0.027692\n",
              "60036  334452    2018-12  ...  648  0.106154\n",
              "\n",
              "[60037 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Sa75D7SPZq",
        "colab_type": "code",
        "outputId": "ca61944a-bcfe-4fa9-c8e8-c66c5b0fea29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train_rand = train.sample(frac=1, random_state=2020).reset_index()\n",
        "print(train_rand['smishing'].head())\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.scatter(train_rand['smishing'].indexㅠ.values, train_rand['smishing'].values, s=1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    1\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: smishing, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAEvCAYAAAA0ITL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nADCY/w/Q5mnINWzNMAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIcTFNanSWBq",
        "colab_type": "code",
        "outputId": "708309b3-43ee-421e-8aa0-f4a056a015d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# 리뷰 문장 추출\n",
        "sentences = train_rand['text']\n",
        "print(sentences[:3])\n",
        "print(len(sentences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    광고 현명한 대출과 현명한 신용관리어느새 성큼 다가온 12월의 계절을 맞아 당사 상...\n",
            "1                 포일 거래감사합니다 고객만족도 조사시 매우동의와 추천 칭찬해주세요\n",
            "2     고객님을 위한 연말 환율우대 이벤트즐거운 연말 해외여행 계획이 있으시다면 내외동지...\n",
            "Name: text, dtype: object\n",
            "60037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ9jZQudSV-9",
        "colab_type": "code",
        "outputId": "84d027fd-37f6-4826-98e0-f7d42446887a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import re\n",
        "def f_re_pat(x):\n",
        "#     print('before :', x)\n",
        "    re_pat_ending = re.compile('(니다)|(세요)|(시오)')\n",
        "    idx = 0\n",
        "    for i in range(10):\n",
        "#         print(idx, x[idx:])\n",
        "        tmp_search = re_pat_ending.search(x[idx:])\n",
        "        if tmp_search!=None:\n",
        "            idx = tmp_search.end() +idx\n",
        "            x = x[:idx] + ' [SEP]' + x[idx:]\n",
        "#             print('after  :', x)\n",
        "            idx += 6    # len(' [SEP]')\n",
        "        else:\n",
        "#             print('None')\n",
        "            break\n",
        "    if x[-6:] != ' [SEP]':    # 마지막 문장을 if문으로 판단하여, [SEP]를 넣어준다.\n",
        "        x = x + ' [SEP]'\n",
        "    return x\n",
        "f_re_pat(train['text'][2])\n",
        "# f_re_pat('안녕하세요. 입니다.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 0415 1422 카드스마트 710000잔액4869889 [SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDheONJ5SV8b",
        "colab_type": "code",
        "outputId": "7378f2fe-55b5-47fb-9f18-9f87f4056fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "import time\n",
        "time_i = time.time()\n",
        "sentences = sentences.apply(f_re_pat).values\n",
        "print(sentences[:5])\n",
        "print(time.time() - time_i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['광고 현명한 대출과 현명한 신용관리어느새 성큼 다가온 12월의 계절을 맞아 당사 상품의 자격기준이 보다 완화되어 상품에 대해 고객님께 간단하게 정보를 전달드립니다 [SEP]경제성장률 마이너스 임금 상승률 제로 소비자 물가지수 상승 모두가 동감하는 현재 상황입니다 [SEP] 경제가 어렵다고 소비와 지출이 없을 순 없습니다 [SEP] 다만 똑똑한 소비와 똑똑한 지출로 마이너스의 함정에 빠지지 않도록 해야 합니다 [SEP]신청방법   터치하셔서 문자로 상담 또는 00시 00분 상담이라고 답장을 보내주시거나 전화를 주시면 친절하고 안전한 상담으로 도움드리겠습니다 [SEP]카카오톡 상담서비스 시행중 citibankloan친구추가 후 상담신청 은행 상품의 특징1 당사 거래가 없으셔도 진행가능2 시중은행권보다 높은한도3 부채가 많다면 부채 통합상품으로 전환 가능4 원리금 균등방식을 이자만 납입하는 만기일시로 전환 가능5 가상 조회를 통해 한도 및 금리를 한 번에 확인 가능 은행 상품안내1 직장인 신용상품한도 최대 1억 4000만 원까지금리 최저 297자격  은행 자체 등급과 기업 리스트에 따라 차등 적용2 채무통합 전환상품한도 연봉 대비 300까지금리 최저 297자격  은행 자체 등급과 기업 리스트에 따라 차등 적용3 새 희망 홀씨한도 최대 3000만 원금리 86812자격 연소득 4500만 원 이하 고객 대상으로 당사 자체 등급에 따라 차등 적용이런 분들께 권해드립니다 [SEP]1 시중은행권에서 기존한도를 모두 사용 중이신 분2 기대출의 원리금 균등방식으로 인해 월 납입금액이 부담스러우신 분3 총 부채금액은 작으나 부채건수가 많아서 관리가 안 되시는 분4 이제라도 대출로 인한 신용등급 관리 및 상승에 관심이 있으신 분신청방법   터광고  [SEP]'\n",
            " ' 포일 거래감사합니다 [SEP] 고객만족도 조사시 매우동의와 추천 칭찬해주세요 [SEP]'\n",
            " ' 고객님을 위한 연말 환율우대 이벤트즐거운 연말 해외여행 계획이 있으시다면 내외동지점과 함께 해주세요 [SEP]주요통화80달러엔화유로화기타통화50위안화홍콩달러 감사합니다 [SEP] 은행 내외동지점 은행내외동 올림 [SEP]'\n",
            " '고객님  은행 독산 스지점입니다 [SEP] 4대연금 수급계좌 신규신청계좌변경타행 시 추첨을 통해 푸짐한 경품을 드립니다 [SEP] 4대연금은  와 함께 안전하고 든든하게 연금수령하세요 [SEP] 고객님 행복한 주말 보내세요 [SEP] 은행독산 올림 [SEP]'\n",
            " '이름없는 오늘이더 멋진추억의시간이 되었으면좋겠습니다 [SEP] 남대문  [SEP]']\n",
            "1.1498966217041016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oymF0l90RrVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SJmTo2YSV5i",
        "colab_type": "code",
        "outputId": "56e1d770-2216-4e8d-b407-f4ec6a2b5605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import time\n",
        "time_i = time.time()\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])\n",
        "print(time.time() - time_i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "광고 현명한 대출과 현명한 신용관리어느새 성큼 다가온 12월의 계절을 맞아 당사 상품의 자격기준이 보다 완화되어 상품에 대해 고객님께 간단하게 정보를 전달드립니다 [SEP]경제성장률 마이너스 임금 상승률 제로 소비자 물가지수 상승 모두가 동감하는 현재 상황입니다 [SEP] 경제가 어렵다고 소비와 지출이 없을 순 없습니다 [SEP] 다만 똑똑한 소비와 똑똑한 지출로 마이너스의 함정에 빠지지 않도록 해야 합니다 [SEP]신청방법   터치하셔서 문자로 상담 또는 00시 00분 상담이라고 답장을 보내주시거나 전화를 주시면 친절하고 안전한 상담으로 도움드리겠습니다 [SEP]카카오톡 상담서비스 시행중 citibankloan친구추가 후 상담신청 은행 상품의 특징1 당사 거래가 없으셔도 진행가능2 시중은행권보다 높은한도3 부채가 많다면 부채 통합상품으로 전환 가능4 원리금 균등방식을 이자만 납입하는 만기일시로 전환 가능5 가상 조회를 통해 한도 및 금리를 한 번에 확인 가능 은행 상품안내1 직장인 신용상품한도 최대 1억 4000만 원까지금리 최저 297자격  은행 자체 등급과 기업 리스트에 따라 차등 적용2 채무통합 전환상품한도 연봉 대비 300까지금리 최저 297자격  은행 자체 등급과 기업 리스트에 따라 차등 적용3 새 희망 홀씨한도 최대 3000만 원금리 86812자격 연소득 4500만 원 이하 고객 대상으로 당사 자체 등급에 따라 차등 적용이런 분들께 권해드립니다 [SEP]1 시중은행권에서 기존한도를 모두 사용 중이신 분2 기대출의 원리금 균등방식으로 인해 월 납입금액이 부담스러우신 분3 총 부채금액은 작으나 부채건수가 많아서 관리가 안 되시는 분4 이제라도 대출로 인한 신용등급 관리 및 상승에 관심이 있으신 분신청방법   터광고  [SEP]\n",
            "['광', '##고', '현', '##명한', '대', '##출', '##과', '현', '##명한', '신', '##용', '##관', '##리', '##어', '##느', '##새', '성', '##큼', '다', '##가', '##온', '12월', '##의', '계', '##절', '##을', '맞', '##아', '당', '##사', '상', '##품', '##의', '자', '##격', '##기', '##준', '##이', '보다', '완', '##화', '##되어', '상', '##품', '##에', '대해', '고', '##객', '##님', '##께', '간', '##단', '##하게', '정', '##보를', '전', '##달', '##드', '##립', '##니다', '[SEP]', '경', '##제', '##성', '##장', '##률', '마', '##이', '##너', '##스', '임', '##금', '상', '##승', '##률', '제', '##로', '소', '##비', '##자', '물', '##가지', '##수', '상', '##승', '모두', '##가', '동', '##감', '##하는', '현재', '상', '##황', '##입', '##니다', '[SEP]', '경', '##제가', '어', '##렵', '##다고', '소', '##비', '##와', '지', '##출', '##이', '없', '##을', '순', '없', '##습', '##니다', '[SEP]', '다만', '똑', '##똑', '##한', '소', '##비', '##와', '똑', '##똑', '##한', '지', '##출', '##로', '마', '##이', '##너', '##스의', '함', '##정에', '빠', '##지', '##지', '않', '##도록', '해', '##야', '합', '##니다', '[SEP]', '신', '##청', '##방', '##법', '터', '##치', '##하', '##셔', '##서', '문', '##자로', '상', '##담', '또는', '00', '##시', '00', '##분', '상', '##담', '##이', '##라고', '답', '##장을', '보', '##내', '##주시', '##거나', '전', '##화를', '주', '##시', '##면', '친', '##절', '##하고', '안', '##전', '##한', '상', '##담', '##으로', '도', '##움', '##드', '##리', '##겠', '##습', '##니다', '[SEP]', '카', '##카', '##오', '##톡', '상', '##담', '##서', '##비스', '시', '##행', '##중', 'cit', '##iban', '##klo', '##an', '##친', '##구', '##추', '##가', '후', '상', '##담', '##신', '##청', '은', '##행', '상', '##품', '##의', '특', '##징', '##1', '당', '##사', '거', '##래', '##가', '없', '##으', '##셔', '##도', '진', '##행', '##가', '##능', '##2', '시', '##중', '##은', '##행', '##권', '##보다', '높은', '##한', '##도', '##3', '부', '##채', '##가', '많다', '##면', '부', '##채', '통', '##합', '##상', '##품', '##으로', '전', '##환', '가', '##능', '##4', '원', '##리', '##금', '균', '##등', '##방', '##식을', '이', '##자', '##만', '납', '##입', '##하는', '만', '##기', '##일', '##시', '##로', '전', '##환', '가', '##능', '##5', '가', '##상', '조', '##회를', '통해', '한', '##도', '및', '금', '##리를', '한', '번', '##에', '확인', '가', '##능', '은', '##행', '상', '##품', '##안', '##내', '##1', '직', '##장', '##인', '신', '##용', '##상', '##품', '##한', '##도', '최대', '1', '##억', '4000', '##만', '원', '##까지', '##금', '##리', '최', '##저', '297', '##자', '##격', '은', '##행', '자', '##체', '등', '##급', '##과', '기', '##업', '리', '##스트', '##에', '따라', '차', '##등', '적', '##용', '##2', '채', '##무', '##통', '##합', '전', '##환', '##상', '##품', '##한', '##도', '연', '##봉', '대', '##비', '300', '##까지', '##금', '##리', '최', '##저', '297', '##자', '##격', '은', '##행', '자', '##체', '등', '##급', '##과', '기', '##업', '리', '##스트', '##에', '따라', '차', '##등', '적', '##용', '##3', '새', '희', '##망', '홀', '##씨', '##한', '##도', '최대', '3000', '##만', '원', '##금', '##리', '868', '##12', '##자', '##격', '연', '##소', '##득', '4500', '##만', '원', '이', '##하', '고', '##객', '대', '##상으로', '당', '##사', '자', '##체', '등', '##급', '##에', '따라', '차', '##등', '적', '##용이', '##런', '분', '##들', '##께', '권', '##해', '##드', '##립', '##니다', '[SEP]', '1', '시', '##중', '##은', '##행', '##권', '##에서', '기', '##존', '##한', '##도를', '모두', '사', '##용', '중', '##이', '##신', '분', '##2', '기', '##대', '##출', '##의', '원', '##리', '##금', '균', '##등', '##방', '##식으로', '인해', '월', '납', '##입', '##금', '##액', '##이', '부', '##담', '##스', '##러', '##우', '##신', '분', '##3', '총', '부', '##채', '##금', '##액', '##은', '작', '##으나', '부', '##채', '##건', '##수가', '많', '##아', '##서', '관', '##리가', '안', '되', '##시', '##는', '분', '##4', '이', '##제', '##라', '##도', '대', '##출', '##로', '인', '##한', '신', '##용', '##등', '##급', '관', '##리', '및', '상', '##승', '##에', '관', '##심', '##이', '있', '##으', '##신', '분', '##신', '##청', '##방', '##법', '터', '##광', '##고', '[SEP]']\n",
            "89.90876817703247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhykAMBJSV2S",
        "colab_type": "code",
        "outputId": "bdb7ac25-b78b-4851-822d-68f9f1ff4e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 라벨 추출\n",
        "labels = train_rand['smishing'].values\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 ... 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmUNlyUrTCad",
        "colab_type": "text"
      },
      "source": [
        "## token2id, padding, attention masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxUcSIsRSxPZ",
        "colab_type": "code",
        "outputId": "7f68e5b3-e441-46a1-a6ae-946bd7661493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "import time\n",
        "time_i = time.time()\n",
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "\n",
        "MAX_LEN = 192#128#512#128#512#191227(금)_01   #128191226(목)\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "print(time.time() - time_i)\n",
        "input_ids[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.207472562789917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  8903,  11664,   9978,  68414,   9069,  52363,  11882,   9978,\n",
              "        68414,   9487,  24974,  20595,  12692,  12965, 118760, 119031,\n",
              "         9434, 119328,   9056,  11287,  37093,  16367,  10459,   8887,\n",
              "        58931,  10622,   9256,  16985,   9067,  12945,   9414,  52951,\n",
              "        10459,   9651,  45465,  12310,  54867,  10739, 106154,   9591,\n",
              "        18227,  16855,   9414,  52951,  10530,  33378,   8888, 118617,\n",
              "       108578, 118683,   8845,  24989,  17594,   9670,  91693,   9665,\n",
              "        89851,  15001,  35115,  48345,    102,   8885,  17730,  17138,\n",
              "        13890,  88350,   9246,  10739,  70162,  12605,   9644,  40032,\n",
              "         9414,  48210,  88350,   9672,  11261,   9448,  29455,  13764,\n",
              "         9299,  69023,  15891,   9414,  48210,  29414,  11287,   9095,\n",
              "       105197,  12178,  26565,   9414,  65649,  58303,  48345,    102,\n",
              "         8885,  54480,   9546, 118879,  85634,   9448,  29455,  12638,\n",
              "         9706,  52363,  10739,   9555,  10622,   9462,   9555, 119081,\n",
              "        48345,    102, 107930,   9145, 118840,  11102,   9448,  29455,\n",
              "        12638,   9145, 118840,  11102,   9706,  52363,  11261,   9246,\n",
              "        10739,  70162,  49319,   9956,  77763,   9388,  12508,  12508,\n",
              "         9523,  71689,   9960,  21711,   9957,  48345,    102,   9487,\n",
              "        40311,  42337,  33768,   9861,  18622,  35506, 119049,  12424,\n",
              "         9297,  57713,   9414, 105462,  20625,  11025,  14040,  11025,\n",
              "        37712,   9414, 105462,  10739,  59894,   9065,  35963,   9356,\n",
              "        31605,  87281,  55534,   9665,  56999,   9689,  14040,  14867,\n",
              "         9781,  58931,  12453,   9521,  16617,  11102,   9414, 105462,\n",
              "        11467,   9087, 119169,  15001,  12692, 118632, 119081,  48345])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTQo0DhYS_G6",
        "colab_type": "code",
        "outputId": "1cc1de58-97ae-4329-adf3-791717eaef55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import time\n",
        "time_i = time.time()\n",
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(len(attention_masks[0]))\n",
        "print(attention_masks[0])\n",
        "print(time.time() - time_i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "192\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "6.5240747928619385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRPgIdmcS_CI",
        "colab_type": "code",
        "outputId": "f8faac7f-432c-4a0c-c838-ea61b340850b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 훈련셋과 검증셋으로 분리\n",
        "nb_samples = 32*4\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids[:nb_samples],\n",
        "                                                                                    labels[:nb_samples], \n",
        "                                                                                    random_state=2018, \n",
        "                                                                                    test_size=0.1)\n",
        "\n",
        "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks[:nb_samples], \n",
        "                                                       input_ids[:nb_samples],\n",
        "                                                       random_state=2018, \n",
        "                                                       test_size=0.1)\n",
        "\n",
        "# 데이터를 파이토치의 텐서로 변환\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "print(train_inputs[0])\n",
        "print(train_labels[0])\n",
        "print(train_masks[0])\n",
        "print(validation_inputs[0])\n",
        "print(validation_labels[0])\n",
        "print(validation_masks[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  9670,  30858, 119121, 108578, 118957,  11664,   8863,  37388,  14523,\n",
            "         16323, 119049,  12424,   9708,  71013,  11467,   8848,  12945,  33188,\n",
            "         48345,    102,   9655,  31503,  41693, 119119,   9899,  13890, 119153,\n",
            "         67527,    102,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "tensor([  8888, 118617, 108578,  11166,  38851,  45987,  18392,   8888, 118617,\n",
            "        108578,  10459,   9420,  18392,  10622,   9708,  71013,  11467,   9766,\n",
            "         35506,  15001,  35115,  48345,    102,   8932, 119023,   8985,   8932,\n",
            "         37712,  79633,   9952,  35866,   9098,  14040,  11664,   9959,  14871,\n",
            "          9966,  70915,  12453,   8865,  47181,  35506,  14040, 118666,   9318,\n",
            "        118853,  48345,    102,   9632,  25549,   9665, 105462,  33077,  14279,\n",
            "          9113,  67527,    102,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcD_-YPNS--l",
        "colab_type": "code",
        "outputId": "6a084788-6d63-43ce-8d0b-508c7e7a22a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "print(train_inputs[0].shape)\n",
        "print(train_labels[0].shape)\n",
        "print('len:', len(train_labels[0].shape))\n",
        "print(train_masks[0].shape)\n",
        "print(validation_inputs[0].shape)\n",
        "print(validation_labels[0].shape)\n",
        "print('len:', len(validation_labels[0].shape))\n",
        "print(validation_masks[0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([192])\n",
            "torch.Size([])\n",
            "len: 0\n",
            "torch.Size([192])\n",
            "torch.Size([192])\n",
            "torch.Size([])\n",
            "len: 0\n",
            "torch.Size([192])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVpKKrB4uCN4",
        "colab_type": "code",
        "outputId": "94bcf64b-a0fc-4f46-b123-dd94be620757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUAHim2uS-6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 배치 사이즈\n",
        "batch_size = 32#8#16#32\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1E8R3EgTOG9",
        "colab_type": "text"
      },
      "source": [
        "# 모델 생성 및 하이퍼파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d0jBUkgTrj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Setting parameters\n",
        "max_len = 128\n",
        "batch_size = 32\n",
        "warmup_ratio = 0\n",
        "num_epochs = 3\n",
        "max_grad_norm = 1\n",
        "log_interval = 10\n",
        "learning_rate =  2e-5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBNYK9tYTcAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps = 1e-8) # eps 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "# scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps=warmup_step, t_total=t_total) 원래이거였는데 바꿔줌\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LeXhdbhTkoE",
        "colab_type": "text"
      },
      "source": [
        "## 훈련 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxC8zX2lTZNo",
        "colab_type": "code",
        "outputId": "aa9722ce-34b1-4450-87ea-5f216f981b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "from tqdm import tqdm, tqdm_notebook\n",
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids,  label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-31a09ad8a45d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_epochs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn3K0BThYYK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}